so this is the actually embedded llm model , its wizard math. i made a python code which checks if its installed and then install it if not , then it checks if the server is running and then run ollama. 
wizard math actually runs into the terminal; 
